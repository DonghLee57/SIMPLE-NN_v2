SIMPLE_NN v2.0.0 (7a83d2a)                                              SEED:        123
----------------------------------------------------------------------------------------
                _____ _ _      _ _ ___  _     _____       __    _ __    _               
               / ____| | \    / | '__ \| |   |  ___|     |  \  | |  \  | |              
              | |___ | |  \  /  | |__) | |   | |___  ___ |   \ | |   \ | |              
               \___ \| |   \/   |  ___/| |   |  ___||___|| |\ \| | |\ \| |              
               ____| | | |\  /| | |    | |___| |___      | | \   | | \   |              
              |_____/|_|_| \/ |_|_|    |_____|_____|     |_|  \__|_|  \__|              

----------------------------------------------------------------------------------------

Input for parameters
Si parameters directory     : params_Si
O  parameters directory     : params_O

Input for neural_network

INPUT DATA
Train                       : True
Train list                  : ./train_list
Valid list                  : ./valid_list
Test                        : False
Add NNP reference to files  : False
Train atomic energy         : False
Use force in traning        : True
Use stress in training      : True
Shuffle dataloader          : True

NETWORK
Nodes                       : 30-30
Activation function type    : sigmoid
Double precision            : True
Use dropout network         : False
Weight initializer          : xavier normal
Use scale                   : True
Use PCA                     : True
Use atomic_weights          : False

OPTIMIZATION
Optimization method         : Adam
Batch size                  : 8
Use full batch              : False
Total traning epoch         : 100
Learning rate               : 0.001
L2_regularization           : 1e-06

LOSS FUNCTION
Scale for loss function     : 1.0
Energy loss function type   : 1
Force loss function type    : 1
Energy coefficient          : 1.0
Force coefficient           : 0.1
Stress coefficient          : 1e-06

LOGGING & SAVING
Show interval               : 10
Print structure RMSE        : False

PARALLELISM
GPU training                : True
Intra op parallelism thread : 1
Inter op parallelism thread : 16
Direct data loading to gpu  : True
# of subprocesses in loading: 0

----------------------------------------------------------------------------------------
cuda is used in model.
Total iteration: 5700 , epoch: 100, batch number: 57, batch size: 8, subprocesses : 0
----------------------------------------------------------------------------------------
Epoch      10 E RMSE(T V) 8.9654e-02 8.9812e-02 F RMSE(T V) 4.8882e-01 4.9505e-01 S RMSE(T V) 1.4936e+01 1.4741e+01 learning_rate: 1.0000e-03
Data load(T V): 7.0426e+00 3.9035e-01 s/epoch Total time(T V): 8.5270e+00 4.5395e-01 s/epoch Elapsed: 5.4197e+01 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      20 E RMSE(T V) 1.9705e-03 1.7527e-03 F RMSE(T V) 4.0720e-01 4.1386e-01 S RMSE(T V) 1.2695e+01 1.2457e+01 learning_rate: 1.0000e-03
Data load(T V): 7.0368e+00 3.9096e-01 s/epoch Total time(T V): 8.5210e+00 4.5463e-01 s/epoch Elapsed: 1.0776e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      30 E RMSE(T V) 1.6900e-03 1.4978e-03 F RMSE(T V) 3.4348e-01 3.5061e-01 S RMSE(T V) 1.1416e+01 1.1160e+01 learning_rate: 1.0000e-03
Data load(T V): 7.0292e+00 3.9024e-01 s/epoch Total time(T V): 8.5130e+00 4.5307e-01 s/epoch Elapsed: 1.6131e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      40 E RMSE(T V) 1.4965e-03 1.3025e-03 F RMSE(T V) 2.9503e-01 3.0223e-01 S RMSE(T V) 1.0840e+01 1.0732e+01 learning_rate: 1.0000e-03
Data load(T V): 7.0441e+00 3.9114e-01 s/epoch Total time(T V): 8.5279e+00 4.5410e-01 s/epoch Elapsed: 2.1491e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      50 E RMSE(T V) 1.3438e-03 1.1168e-03 F RMSE(T V) 2.5782e-01 2.6481e-01 S RMSE(T V) 9.1667e+00 9.0590e+00 learning_rate: 1.0000e-03
Data load(T V): 7.0448e+00 3.9103e-01 s/epoch Total time(T V): 8.5300e+00 4.5429e-01 s/epoch Elapsed: 2.6847e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      60 E RMSE(T V) 1.1931e-03 1.0299e-03 F RMSE(T V) 2.2993e-01 2.3684e-01 S RMSE(T V) 7.9051e+00 7.9087e+00 learning_rate: 1.0000e-03
Data load(T V): 7.0376e+00 3.9026e-01 s/epoch Total time(T V): 8.5251e+00 4.5329e-01 s/epoch Elapsed: 3.2203e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      70 E RMSE(T V) 1.0826e-03 9.0380e-04 F RMSE(T V) 2.0426e-01 2.1144e-01 S RMSE(T V) 7.1940e+00 7.2484e+00 learning_rate: 1.0000e-03
Data load(T V): 7.0293e+00 3.9158e-01 s/epoch Total time(T V): 8.5109e+00 4.5507e-01 s/epoch Elapsed: 3.7558e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      80 E RMSE(T V) 1.0006e-03 8.3808e-04 F RMSE(T V) 1.8612e-01 1.9350e-01 S RMSE(T V) 7.2222e+00 7.2448e+00 learning_rate: 1.0000e-03
Data load(T V): 7.0431e+00 3.9188e-01 s/epoch Total time(T V): 8.5285e+00 4.5549e-01 s/epoch Elapsed: 4.2919e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch      90 E RMSE(T V) 8.8402e-04 7.5901e-04 F RMSE(T V) 1.7328e-01 1.8095e-01 S RMSE(T V) 5.9172e+00 6.1158e+00 learning_rate: 1.0000e-03
Data load(T V): 7.0489e+00 3.9222e-01 s/epoch Total time(T V): 8.5391e+00 4.5606e-01 s/epoch Elapsed: 4.8281e+02 s
----------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------
Epoch     100 E RMSE(T V) 8.4499e-04 7.7228e-04 F RMSE(T V) 1.6082e-01 1.6839e-01 S RMSE(T V) 6.0647e+00 6.2442e+00 learning_rate: 1.0000e-03
Data load(T V): 7.1274e+00 3.9028e-01 s/epoch Total time(T V): 8.6176e+00 4.5381e-01 s/epoch Elapsed: 5.3651e+02 s
----------------------------------------------------------------------------------------
Best loss lammps potential written at 99 epoch
Elapsed time in training: 544.8022453784943 s.
----------------------------------------------------------------------------------------
Total wall time: 544.8154385089874 s.
