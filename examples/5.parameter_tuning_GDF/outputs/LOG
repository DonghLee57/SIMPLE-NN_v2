SIMPLE_NN v20.2 (unknown)
----------------------------------------------------------------------------------------------
                   _____ _ _      _ _ ___  _     _____       __    _ __    _                  
                  / ____| | \    / | '__ \| |   |  ___|     |  \  | |  \  | |                 
                 | |___ | |  \  /  | |__) | |   | |___  ___ |   \ | |   \ | |                 
                  \___ \| |   \/   |  ___/| |   |  ___||___|| |\ \| | |\ \| |                 
                  ____| | | |\  /| | |    | |___| |___      | | \   | | \   |                 
                 |_____/|_|_| \/ |_|_|    |_____|_____|     |_|  \__|_|  \__|                 
                                                                     ver2.0.0                 
----------------------------------------------------------------------------------------------


----------------------------------------------------------------------------------------------
Input for neural_network

Si parameters directory         : params_Si
O  parameters directory         : params_O

  INPUT DATA
train                           : True
train list                      : ./train_list
valid list                      : ./valid_list
test                            : False
add NNP reference to files      : False
train atomic energy             : False
shuffle dataloader              : True

  NETWORK
nodes                           : 30-30
use force in traning            : True
use stress in training          : False
double precision                : True
activation function type        : sigmoid
use dropout network             : False
weight initializer              : xavier normal
use pca in traning              : True
use scale in traning            : True
use gdf in traning              : True

Weight modifier type      : modified sigmoid
 ---parameters for weight modifier--- 
Si  params  :  (b = 1.0)  (c = 35.0) 
O   params  :  (b = 1.0)  (c = 74.0) 

  OPTIMIZATION
optimization method             : Adam
batch size                      : 10
use full batch for input        : False
total traning epoch             : 100
learning rate                   : 0.001
regularization (L2)             : 1e-06

  LOSS FUNCTION
energy coefficient              : 1.0
force coefficient               : 0.1
scale for loss function         : 1.0
energy loss function type       : 0
force  loss function type       : 1

  LOGGING & SAVING
interval (epoch) for show       : 10
print structure RMSE            : False

  PARALLELISM
load data directly to gpu       : False
number of workers in dataloader : 0
CPU core number in pytorch      : 0
Thread number in pytorch        : 0

----------------------------------------------------------------------------------------------
Parallelism intra_thread : 1 inter_thread : 16
USE cuda IN MODEL
INITIALIZATION MODEL DONE.
Total training iteration : 4500 , epoch : 100, batch number : 45, batch size : 10, workers : 0
----------------------------------------------------------------------------------------------
Epoch      10 E RMSE(T V) 4.8975e-01 4.8948e-01 F RMSE(T V) 4.7743e-01 4.8440e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6466e+01 3.1451e+00 s/epoch Total time(T V): 6.2790e+01 3.3409e+00 s/epoch Elapsed: 3.9228e+02 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      20 E RMSE(T V) 2.6974e-03 2.2251e-03 F RMSE(T V) 4.0953e-01 4.2133e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6565e+01 3.1480e+00 s/epoch Total time(T V): 6.2896e+01 3.3440e+00 s/epoch Elapsed: 7.8466e+02 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      30 E RMSE(T V) 1.8193e-03 1.4991e-03 F RMSE(T V) 3.7303e-01 3.8656e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6873e+01 3.1816e+00 s/epoch Total time(T V): 6.3258e+01 3.3790e+00 s/epoch Elapsed: 1.1781e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      40 E RMSE(T V) 1.6509e-03 1.3543e-03 F RMSE(T V) 3.4016e-01 3.5324e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6962e+01 3.1642e+00 s/epoch Total time(T V): 6.3352e+01 3.3624e+00 s/epoch Elapsed: 1.5729e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      50 E RMSE(T V) 1.5353e-03 1.3810e-03 F RMSE(T V) 3.0603e-01 3.1824e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6572e+01 3.1698e+00 s/epoch Total time(T V): 6.2906e+01 3.3661e+00 s/epoch Elapsed: 1.9654e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      60 E RMSE(T V) 1.3982e-03 1.3324e-03 F RMSE(T V) 2.7657e-01 2.8725e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6587e+01 3.1638e+00 s/epoch Total time(T V): 6.2932e+01 3.3596e+00 s/epoch Elapsed: 2.3583e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      70 E RMSE(T V) 1.2855e-03 1.2803e-03 F RMSE(T V) 2.5444e-01 2.6532e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6569e+01 3.2078e+00 s/epoch Total time(T V): 6.2904e+01 3.4036e+00 s/epoch Elapsed: 2.7509e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      80 E RMSE(T V) 1.2403e-03 1.2360e-03 F RMSE(T V) 2.3768e-01 2.4835e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6449e+01 3.1483e+00 s/epoch Total time(T V): 6.2786e+01 3.3441e+00 s/epoch Elapsed: 3.1439e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch      90 E RMSE(T V) 1.1524e-03 1.1948e-03 F RMSE(T V) 2.2053e-01 2.3092e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6878e+01 3.1645e+00 s/epoch Total time(T V): 6.3231e+01 3.3603e+00 s/epoch Elapsed: 3.5372e+03 s
----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
Epoch     100 E RMSE(T V) 1.1118e-03 1.2084e-03 F RMSE(T V) 2.0916e-01 2.1876e-01 learning_rate: 1.0000e-03
Data load(T V): 5.6715e+01 3.1795e+00 s/epoch Total time(T V): 6.3062e+01 3.3758e+00 s/epoch Elapsed: 3.9305e+03 s
----------------------------------------------------------------------------------------------
Best loss lammps potential written at 100 epoch
train done. 3978.5758645534515 seconds elapsed
total wall time 3979.0242302417755 seconds
